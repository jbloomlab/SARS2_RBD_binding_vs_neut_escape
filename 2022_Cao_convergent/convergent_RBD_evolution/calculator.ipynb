{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca6c734-a49b-44f6-9ad8-d5294c561de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import time\n",
    "neut2codon = {\n",
    "    \"D614G_IC50\":\"allowed_muts/mut1_SARSCoV2_WuhanHu1_Spike.csv\",\n",
    "    \"BA1_IC50\":\"allowed_muts/mut1_BA.1_Omicron_baseline_EPI_ISL_10000028.csv\",\n",
    "    \"BA2_IC50\":\"allowed_muts/mut1_BA.2_Omicron_baseline_EPI_ISL_10000005.csv\",\n",
    "    \"BA2_75_IC50\":\"allowed_muts/mut1_BA.2.75_EPI_ISL_13302209.csv\",\n",
    "    \"BA5_IC50\":\"allowed_muts/mut1_BA.4_BA.5_EPI_ISL_11207535.csv\",\n",
    "}\n",
    "\n",
    "neut2se = {\n",
    "    \"D614G_IC50\":\"bind_expr/bind_expr_WT.csv\",\n",
    "    \"BA1_IC50\":\"bind_expr/bind_expr_BA1.csv\",\n",
    "    \"BA2_IC50\":\"bind_expr/bind_expr_BA2.csv\",\n",
    "    \"BA2_75_IC50\":\"bind_expr/bind_expr_BA2.csv\",\n",
    "    \"BA5_IC50\":\"bind_expr/bind_expr_BA2.csv\",\n",
    "}\n",
    "mut_for_bind_expr = {\n",
    "    'BA2_75_IC50': [(339, 'H'), (446, 'S'), (460, 'K'), (493, 'Q')],\n",
    "    'BA5_IC50': [(452, 'R'), (486, 'V'), (493, 'Q')],\n",
    "}\n",
    "\n",
    "for strain in mut_for_bind_expr:\n",
    "    data = pd.read_csv(neut2se[strain]).assign(bias_e = 0.0,bias_b=0.0)\n",
    "    for site, mut in mut_for_bind_expr[strain]:\n",
    "        expr = data.query('site == @site and mutation == @mut')['expr_avg'].item()\n",
    "        bind = data.query('site == @site and mutation == @mut')['bind_avg'].item()\n",
    "        data.loc[data['site'] == site, 'bias_e'] += expr\n",
    "        data.loc[data['site'] == site, 'bias_b'] += bind\n",
    "    data['expr_avg'] -= data['bias_e']\n",
    "    data['bind_avg'] -= data['bias_b']\n",
    "    data.drop(columns=['bias_e','bias_b']).to_csv(\"mut_approx_\"+strain+\".csv\", index=None)\n",
    "    neut2se[strain] = \"mut_approx_\"+strain+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853244fc-755f-46fd-b922-005fd5c7c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average based on IC50\n",
    "scores_r = pd.read_csv(\"use_res_clean.csv\")\n",
    "use_abs = np.unique(scores_r['antibody'])\n",
    "\n",
    "data = pd.read_csv(\"src_neut_data.csv\", index_col=0)[[\n",
    "    \"source\",\n",
    "    \"D614G_IC50\", \"BA1_IC50\",\"BA2_IC50\",\"BA5_IC50\",\"BA2_75_IC50\"\n",
    "]].query('antibody in @use_abs')\n",
    "\n",
    "_srcs = data['source'].to_list()\n",
    "\n",
    "data = data.assign(Usrc = [\n",
    "    \"mouse\" if \"mouse\" in _srcs[i] else (\n",
    "        \"WT\" if _srcs[i][0:2] == \"WT\" else (\n",
    "            \"SARS\" if _srcs[i][0:4] == \"SARS\" else (\n",
    "                \"BA2\" if _srcs[i][0:4] == \"BA.2\" else (\n",
    "                    \"BA1\" if _srcs[i][0:4] == \"BA.1\" else (\n",
    "                        \"BA5\" if _srcs[i][0:4] == \"BA.5\" else \"???\"\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )for i in range(len(_srcs))])\n",
    "\n",
    "\n",
    "for term in [\n",
    "    \"D614G_IC50\", \"BA1_IC50\",\"BA2_IC50\",\"BA5_IC50\",\"BA2_75_IC50\"\n",
    "]:\n",
    "    _x = data[term].to_list()\n",
    "    data[term] = [10.0 if (y[0] == '>' or y[0:3] == 'Inf') else (np.nan if y == '--' else max(0.0005,min(10.0,float(y)))) for y in _x]\n",
    "\n",
    "data = data.query('not (Usrc == \"???\" or Usrc == \"mouse\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef1f751-c04d-421a-bd10-9e79684dfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logomaker\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "def plot_res_logo(res, prefix, shownames={}, rownames=None, site_thres=0.0, force_plot_sites = None, force_ylim = None, width=None):\n",
    "    flat_res = res.pivot(index=['antibody', 'site'], columns='mutation', values='mut_escape').fillna(0)\n",
    "    sites_mean_score = flat_res.mean(axis=1)\n",
    "    sites_total_score = flat_res.sum(axis=1)\n",
    "    _ = sites_total_score[sites_total_score>site_thres].index\n",
    "    strong_sites = np.unique(np.array(sorted([i[1] for i in _])))\n",
    "    print(strong_sites)\n",
    "\n",
    "    plot_sites = strong_sites\n",
    "    plot_sites = plot_sites[plot_sites < 520].astype(int)\n",
    "    print(plot_sites)\n",
    "    \n",
    "    if force_plot_sites is not None:\n",
    "        plot_sites = force_plot_sites\n",
    "    \n",
    "    flat_res = flat_res[flat_res.index.isin(plot_sites, level=1)]\n",
    "\n",
    "    _ = pd.DataFrame(sites_total_score)\n",
    "    _.columns = ['value']\n",
    "    _['site'] = [i[1] for i in _.index]\n",
    "    _['antibody'] = [i[0] for i in _.index]\n",
    "\n",
    "    if rownames is not None:\n",
    "        Abs = rownames\n",
    "    else:\n",
    "        Abs = np.unique([i[0] for i in flat_res.index])\n",
    "    print(Abs)\n",
    "    Npages = len(Abs)//10 + 1\n",
    "    if width is None:\n",
    "        width=30\n",
    "    with PdfPages(prefix+'_aa_logo.pdf') as pdf:\n",
    "        for p in range(Npages):\n",
    "            Abs_p = Abs[p*10:min(len(Abs),(p+1)*10)]\n",
    "            fig = plt.figure(figsize=(width,len(Abs_p)*4.6)).subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "            site2pos = {}\n",
    "            for i in range(len(plot_sites)):\n",
    "                site2pos[plot_sites[i]] = i\n",
    "\n",
    "            for i in range(len(Abs_p)):\n",
    "                ab = Abs_p[i]\n",
    "                _ = flat_res.query('antibody == @ab').droplevel(0)\n",
    "                add_sites = np.setdiff1d(plot_sites, _.index)\n",
    "                for _site in add_sites:\n",
    "                    _.loc[_site,:] = 0.0\n",
    "                _ = _.sort_index()\n",
    "                _.index = range(len(_))\n",
    "                ax = plt.subplot(len(Abs_p), 1, i+1)\n",
    "                logo = logomaker.Logo(_,\n",
    "                               ax=ax, \n",
    "                               color_scheme='dmslogo_funcgroup', \n",
    "                               vpad=.1, \n",
    "                               width=.8)\n",
    "                logo.style_xticks(anchor=1, spacing=1, rotation=90, fontsize=16)\n",
    "                _max = np.sum(_.to_numpy(), axis=1).max()\n",
    "                # ax.set_xticklabels(plot_sites[1::2])\n",
    "                ax.set_xticklabels(plot_sites)\n",
    "                \n",
    "                ax.set_yticks([])\n",
    "                ax.tick_params(axis='both', which='both', length=0)\n",
    "                ax.yaxis.set_tick_params(labelsize=20)\n",
    "                if ab in shownames:\n",
    "                    ax.set_title(shownames[ab], fontsize=8, fontweight=\"bold\")\n",
    "                else:\n",
    "                    ax.set_title(ab, fontsize=8, fontweight=\"bold\")\n",
    "            pdf.savefig()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf2cb4b-9285-42e1-a2b2-9dbfd3a45e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_calc(use_ab_src, use_neut, A_adv = True, A_codon = True, E=1.0, B=1.0, use_log=False, use_max=False, use_norm=False, logo=False, return_df=False):\n",
    "    use_codon = pd.read_csv(neut2codon[use_neut])\n",
    "    neut_data = data[use_neut].to_dict()\n",
    "\n",
    "    single_mut_effects = pd.read_csv(neut2se[use_neut]).assign(coef=lambda x: [y for y in np.exp(x['expr_avg']*E+x['bind_avg']*B)])\n",
    "    # single_mut_effects = pd.read_csv(neut2se[use_neut]).assign(coef=lambda x: [min(1.0, y) for y in np.exp(x['expr_avg']*E+x['bind_avg']*B)])\n",
    "    single_mut_effects.index = single_mut_effects['site'].astype('str') + single_mut_effects['mutation']\n",
    "    single_mut_effects = single_mut_effects['coef'].to_dict()\n",
    "\n",
    "    _umuts = set()\n",
    "    for i in range(len(use_codon)):\n",
    "        _ms = use_codon['mut1'][i]\n",
    "        for x in _ms:\n",
    "            _umuts.add(str(use_codon['pos'][i])+x)\n",
    "\n",
    "    _uabs = set(data.query('Usrc in @use_ab_src').index.to_list())\n",
    "\n",
    "    scores = scores_r.assign(site_mut = lambda x: x['site'].astype(str)+x['mutation']).query('antibody in @_uabs').assign(\n",
    "        adv_weight = (lambda x: [single_mut_effects[y] for y in x['site_mut']]) if A_adv else 1.0,\n",
    "        codon_weight = (lambda x: [(1.0 if y in _umuts else 0.0) for y in x['site_mut'].to_list()]) if A_codon else 1.0\n",
    "    )\n",
    "    \n",
    "    if use_norm:\n",
    "        scores = scores.assign(escape_max = lambda x: x.groupby('antibody')['mut_escape'].transform('max')).assign(\n",
    "            mut_escape = lambda x: x['mut_escape']/x['escape_max']).drop(columns=['escape_max'])\n",
    "    \n",
    "    if use_log:\n",
    "        scores = scores.assign(neut_weight = lambda x: [(0.0 if np.isnan(neut_data[y]) else max(0.0,np.log10(1.0/min(1.0,neut_data[y])))) for y in x['antibody']])\n",
    "    else:\n",
    "        scores = scores.assign(neut_weight = lambda x: [(0.0 if np.isnan(neut_data[y]) else 1.0/neut_data[y]) for y in x['antibody']])\n",
    "    \n",
    "    scores = scores.assign(\n",
    "        mut_escape_adj = lambda x: x['mut_escape'] * x['neut_weight'] * x['adv_weight'] * x['codon_weight']\n",
    "    )\n",
    "    _title = (\"src: \"+'+'.join(use_ab_src)+\n",
    "              ' weight: '+use_neut+' expr_bind:'+str(A_adv)+\n",
    "              ' codon:'+str(A_codon)+' log:'+str(use_log)+\n",
    "              ' norm:'+str(use_norm)+' max:'+str(use_max)+\n",
    "              ' Expr:'+str(E)+' Bind:'+str(B))\n",
    "    \n",
    "    if logo:\n",
    "        scores = scores.groupby(['site','mutation']).sum()['mut_escape_adj'].reset_index().assign(antibody=_title)\n",
    "        scores['mut_escape_adj'] = scores['mut_escape_adj']/scores['mut_escape_adj'].max()\n",
    "        return scores\n",
    "    \n",
    "    if use_max:\n",
    "        site_avg = scores.groupby(['site', 'antibody']).max()['mut_escape_adj'].reset_index().groupby('site').sum().reset_index()\n",
    "    else:\n",
    "        site_avg = scores.groupby(['site', 'mutation']).sum()['mut_escape_adj'].reset_index().groupby('site').sum().reset_index()\n",
    "    site_avg['mut_escape_adj'] = site_avg['mut_escape_adj']/site_avg['mut_escape_adj'].max()\n",
    "    \n",
    "    if return_df:\n",
    "        return site_avg.assign(\n",
    "            absrc = '+'.join(use_ab_src), weight = use_neut, is_expr_bind = A_adv, is_codon = A_codon, \n",
    "            is_neut_log = use_log, is_norm = use_norm, is_max = use_max, expr_coef = E, bind_coef = B\n",
    "        )\n",
    "    \n",
    "    p = (\n",
    "        ggplot(site_avg, aes('site', 'mut_escape_adj')) + \n",
    "        geom_line() + geom_point()+ theme_classic() + theme(\n",
    "            axis_text_y=element_blank(),\n",
    "            axis_ticks_major_y=element_blank(),figure_size=(12,3),\n",
    "            axis_text_x=element_text(angle=90)\n",
    "        )+scale_x_continuous(breaks=range(331,531,2))+\n",
    "        ylab('weighted escape score')+xlab('RBD residues')+ggtitle(_title)+\n",
    "        geom_text(site_avg.query('mut_escape_adj > 0.2'), aes(label='site'), #nudge_y=0.05, \n",
    "                                adjust_text={'expand_points': (2, 2), 'arrowprops': {'arrowstyle': '-'}})\n",
    "    )\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd3868b9-31be-47d0-ac36-a3754b4316fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[346 348 352 354 356 369 378 406 408 417 420 439 444 445 446 447 448 449\n",
      " 450 452 455 456 460 462 468 472 473 483 484 485 486 487 490 493 494 496\n",
      " 499 503]\n",
      "[346 348 352 354 356 369 378 406 408 417 420 439 444 445 446 447 448 449\n",
      " 450 452 455 456 460 462 468 472 473 483 484 485 486 487 490 493 494 496\n",
      " 499 503]\n",
      "['src: WT weight: D614G_IC50 expr_bind:True codon:True log:True norm:True max:False Expr:1.0 Bind:1.0'\n",
      " 'src: WT+BA1+BA2+BA5 weight: BA2_75_IC50 expr_bind:True codon:True log:True norm:True max:False Expr:1.0 Bind:1.0'\n",
      " 'src: WT+BA1+BA2+BA5 weight: BA5_IC50 expr_bind:True codon:True log:True norm:True max:False Expr:1.0 Bind:1.0'\n",
      " 'src: WT+BA1+BA2+BA5 weight: BQ1_1_IC50 expr_bind:True codon:True log:True norm:True max:False Expr:1.0 Bind:1.0'\n",
      " 'src: WT+BA1+BA2+BA5 weight: XBB_IC50 expr_bind:True codon:True log:True norm:True max:False Expr:1.0 Bind:1.0']\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for use_ab_src, use_neut in [(['WT'], 'D614G_IC50'),\n",
    "                             (['WT','BA1','BA2','BA5'], \"BA2_75_IC50\"),(['WT','BA1','BA2','BA5'], \"BA5_IC50\"),\n",
    "                             # (['BA2'],'BA2_IC50'), \n",
    "                             # (['BA5'],'BA5_IC50'), \n",
    "                             # (['WT','BA1'], 'BA1_IC50'), (['WT','BA1'], 'BA2_IC50'),\n",
    "                             # (['WT','BA1','BA2'], 'BA2_IC50'),\n",
    "                             # (['WT','BA1','BA2'], 'BA5_IC50'),\n",
    "                            ]:\n",
    "    ts = do_calc(use_ab_src, use_neut, A_adv = True, A_codon = True, use_log=True, \n",
    "                          E=1.0, B=1.0,\n",
    "                 use_norm=True, use_max=False, logo=True)\n",
    "    ts.columns = ['site', 'mutation', 'mut_escape','antibody']\n",
    "    df.append(ts)\n",
    "plot_res_logo(pd.concat(df), \"logo\", site_thres=0.15, width=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fa3e99e7-434f-402d-9094-dec6eaba37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject to R for plot\n",
    "\n",
    "xx = \"sum\"\n",
    "\n",
    "df = []\n",
    "for use_ab_src in [[\"WT\"], [\"WT\", \"BA1\"], [\"WT\", \"BA1\", \"BA2\"], [\"WT\", \"BA1\", \"BA2\", \"BA5\"], ['BA1'], [\"BA2\"], [\"BA5\"], [\"BA2\", \"BA5\"]]:\n",
    "    for use_neut in [\"D614G_IC50\", \"BA1_IC50\", \"BA2_IC50\", \"BA2_75_IC50\", \"BA5_IC50\",\"BQ1_1_IC50\",\"XBB_IC50\"]:\n",
    "        # plots.append(do_calc(use_ab_src, use_neut))\n",
    "        df.append(do_calc(use_ab_src, use_neut, A_adv = True, A_codon = True, use_log=True,\n",
    "                          E=1.0, B=1.0,\n",
    "                          use_norm=True, use_max=(xx == \"max\"), return_df=True))\n",
    "\n",
    "pd.concat(df).to_csv(\"tmp_data-\"+xx+\".csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COVID",
   "language": "python",
   "name": "covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
